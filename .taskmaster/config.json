{
  "models": {
    "main": {
      "provider": "claude-code",
      "modelId": "sonnet",
      "maxTokens": 64000,
      "temperature": 0.2
    },
    "research": {
      "provider": "gemini-cli",
      "modelId": "gemini-2.5-pro",
      "maxTokens": 65536,
      "temperature": 0.1
    },
    "fallback": {
      "provider": "gemini-cli",
      "modelId": "gemini-2.5-pro",
      "maxTokens": 65536,
      "temperature": 0.2
    }
  },
  "global": {
    "logLevel": "info",
    "debug": false,
    "defaultNumTasks": 10,
    "defaultSubtasks": 5,
    "defaultPriority": "medium",
    "projectName": "Taskmaster",
    "ollamaBaseURL": "http://localhost:11434/api",
    "bedrockBaseURL": "https://bedrock.us-east-1.amazonaws.com",
    "responseLanguage": "korean",
    "defaultTag": "master",
    "azureOpenaiBaseURL": "https://your-endpoint.openai.azure.com/",
    "userId": "1234567890"
  },
  "claudeCode": {
    "maxTurns": 5,
    "customSystemPrompt": "You are a helpful assistant focused on code quality",
    "appendSystemPrompt": "Always follow coding best practices",
    "permissionMode": "default", 
    "allowedTools": ["Read", "LS"],
    "disallowedTools": ["Write", "Edit"],
    "mcpServers": {
      "sequential-thinking": {
        "command": "cmd",
        "args": [
          "/c",
          "npx",
          "-y",
          "@modelcontextprotocol/server-sequential-thinking"
        ]
      },
      "Context7": {
        "command": "cmd",
        "args": [
          "/c",
          "npx",
          "-y",
          "@upstash/context7-mcp"
        ],
        "description": ""
      }    
    }
  },
  "commandSpecific": {
    "parse-prd": {
      "maxTurns": 10,
      "customSystemPrompt": "You are a task breakdown specialist"
    },
    "analyze-complexity": {
      "maxTurns": 3,
      "appendSystemPrompt": "Focus on identifying bottlenecks"
    }
  },
  "참고":"https://github.com/eyaltoledano/claude-task-master/blob/main/docs/examples/claude-code-usage.md"
}